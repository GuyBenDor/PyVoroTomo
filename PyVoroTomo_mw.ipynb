{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pykonal\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import scipy.spatial\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "EARTH_RADIUS = 6371.\n",
    "DTYPE_REAL   = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class VelocityModel(object):\n",
    "    def __init__(self, grid, velocity):\n",
    "        self.grid     = grid\n",
    "        self.velocity = velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo2sph(arr):\n",
    "    '''\n",
    "    Map Geographical coordinates to spherical coordinates.\n",
    "    '''\n",
    "    geo = np.array(arr, dtype=DTYPE_REAL)\n",
    "    sph = np.empty_like(geo)\n",
    "    sph[...,0] = EARTH_RADIUS - geo[...,2]\n",
    "    sph[...,1] = np.pi/2 - np.radians(geo[...,0])\n",
    "    sph[...,2] = np.radians(geo[...,1])\n",
    "    return (sph)\n",
    "\n",
    "\n",
    "def sph2xyz(arr):\n",
    "    '''\n",
    "    Map spherical coordinates to Cartesian coordinates.\n",
    "    '''\n",
    "    sph = np.array(arr, dtype=DTYPE_REAL)\n",
    "    xyz = np.empty_like(sph)\n",
    "    xyz[...,0] = sph[...,0] * np.sin(sph[...,1]) * np.cos(sph[...,2])\n",
    "    xyz[...,1] = sph[...,0] * np.sin(sph[...,1]) * np.sin(sph[...,2])\n",
    "    xyz[...,2] = sph[...,0] * np.cos(sph[...,1])\n",
    "    return (xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    Main.\n",
    "    '''\n",
    "    argc                   = load_argc()\n",
    "    params                 = load_params()\n",
    "    df_events, df_arrivals = load_event_data(argc, params)\n",
    "    df_stations            = load_network_data(argc)\n",
    "    vmodel                 = load_initial_velocity_model(params)\n",
    "    payload                = dict(\n",
    "        events   = df_events,\n",
    "        arrivals = df_arrivals,\n",
    "        stations = df_stations,\n",
    "        vmodel   = vmodel\n",
    "    )\n",
    "    # Iteratively invert data\n",
    "    for i in range(params['niter']):\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            payload['temp_dir'] = temp_dir\n",
    "            vmodel = iterate_inversion(params, payload)\n",
    "        return (vmodel)\n",
    "\n",
    "\n",
    "def generate_projection_matrix(grid, ncell=300):\n",
    "    '''\n",
    "    Generate the matrix to project each rectilinear grid node to its\n",
    "    host Voronoi cell.\n",
    "    '''\n",
    "    vcells = generate_voronoi_cells(grid, ncell)\n",
    "    dist   = scipy.spatial.distance.cdist(\n",
    "        sph2xyz(grid.nodes.reshape(-1, 3)), \n",
    "        sph2xyz(vcells)\n",
    "    )\n",
    "    colid = np.argmin(dist, axis=1)\n",
    "    rowid = np.arange(np.prod(grid.nodes.shape[:-1]))\n",
    "    \n",
    "    Gp = scipy.sparse.coo_matrix(\n",
    "        (np.ones(np.prod(grid.nodes.shape[:-1]),), (rowid, colid)),\n",
    "        shape=(np.prod(grid.nodes.shape[:-1]), ncell)\n",
    "    )\n",
    "    return (vcells, Gp)\n",
    "\n",
    "\n",
    "def generate_voronoi_cells(grid, ncell):\n",
    "    '''\n",
    "    Generate a random set of points representing the centers of Voronoi cells.\n",
    "    '''\n",
    "    delta = (grid.max_coords - grid.min_coords)\n",
    "    return (np.random.rand(ncell, 3) * delta + grid.min_coords)\n",
    "\n",
    "def find_ray_idx(ray, vcells):\n",
    "    '''\n",
    "    Determine the index of the Voronoi cell hosting each point on\n",
    "    the ray path.\n",
    "    '''\n",
    "    dist = scipy.spatial.distance.cdist(sph2xyz(ray), sph2xyz(vcells))\n",
    "    argmin = np.argmin(dist, axis=1)\n",
    "    idxs, counts = np.unique(argmin, return_counts=True)\n",
    "    return (idxs, counts)\n",
    "\n",
    "\n",
    "def init_farfield(vmodel):\n",
    "    '''\n",
    "    Initialize the far-field EikonalSolver with the given velocity model.\n",
    "    '''\n",
    "    far_field                      = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    far_field.vgrid.min_coords     = vmodel.grid.min_coords\n",
    "    far_field.vgrid.node_intervals = vmodel.grid.node_intervals\n",
    "    far_field.vgrid.npts           = vmodel.grid.npts\n",
    "    far_field.vv                   = vmodel.velocity\n",
    "    return (far_field)\n",
    "\n",
    "def init_nearfield(far_field, origin):\n",
    "    '''\n",
    "    Initialize the near-field EikonalSolver.\n",
    "    \n",
    "    :param origin: Station location in spherical coordinates.\n",
    "    :type origin: (float, float, float)\n",
    "    \n",
    "    :return: Near-field EikonalSolver\n",
    "    :rtype: pykonal.EikonalSolver\n",
    "    '''\n",
    "    drho                            = far_field.vgrid.node_intervals[0] / 5\n",
    "    near_field                      = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    near_field.vgrid.min_coords     = drho, 0, 0\n",
    "    near_field.vgrid.node_intervals = drho, np.pi/20, np.pi/20\n",
    "    near_field.vgrid.npts           = 100, 21, 40\n",
    "    near_field.transfer_velocity_from(far_field, origin)\n",
    "    vvi = pykonal.LinearInterpolator3D(near_field.vgrid, near_field.vv)\n",
    "\n",
    "    for it in range(near_field.pgrid.npts[1]):\n",
    "        for ip in range(near_field.pgrid.npts[2]):\n",
    "            idx = (0, it, ip)\n",
    "            near_field.uu[idx]     = near_field.pgrid[idx + (0,)] / vvi(near_field.pgrid[idx])\n",
    "            near_field.is_far[idx] = False\n",
    "            near_field.close.push(*idx)\n",
    "    return (near_field)\n",
    "\n",
    "\n",
    "def station_generator(payload):\n",
    "    for station_id in payload['df_obs'].index.unique(level='station_id'):\n",
    "        yield (station_id, payload)\n",
    "    \n",
    "    \n",
    "def iterate_inversion(params, payload):\n",
    "    '''\n",
    "    Invert data and update *vmodel*.\n",
    "    '''\n",
    "    dv = [] \n",
    "    # Iterate over number of realizations.\n",
    "    df_stations = payload['stations']\n",
    "    for i in range(params['nreal']):\n",
    "        print(f'Realization #{i+1}')\n",
    "        vcells, G_proj  = generate_projection_matrix(payload['vmodel'].grid, params['ncell'])\n",
    "        df_obs          = sample_observed_data(params, payload)\n",
    "        station_payload = dict(\n",
    "            temp_dir    = payload['temp_dir'],\n",
    "            df_obs      = df_obs,\n",
    "            df_stations = df_stations,\n",
    "            vmodel      = payload['vmodel'],\n",
    "            events      = payload['events'],\n",
    "            vcells      = vcells\n",
    "        )\n",
    "        with mp.Pool(processes=params['nthreads']) as pool:\n",
    "            pool_output = pool.map(process_station, station_generator(station_payload))\n",
    "\n",
    "        dobs         = np.array(sum([out[0] for out in pool_output], []))\n",
    "        col_idx_proj = np.array(sum([out[1] for out in pool_output], []))\n",
    "        nseg         = np.array(sum([out[2] for out in pool_output], []))\n",
    "        row_idx_proj = np.array([i for i in range(len(nseg)) for j in range(nseg[i])])\n",
    "        nonzero_proj = np.array(sum([out[3] for out in pool_output], []))\n",
    "\n",
    "        G = scipy.sparse.coo_matrix(\n",
    "            (nonzero_proj, (row_idx_proj, col_idx_proj)), \n",
    "            shape=(len(nseg), params['ncell'])\n",
    "        )\n",
    "        \n",
    "\n",
    "        atol    = 1e-3\n",
    "        btol    = 1e-4\n",
    "        maxiter = 100\n",
    "        conlim  = 50\n",
    "        damp    = 1.0\n",
    "\n",
    "        x       = scipy.sparse.linalg.lsmr(G, dobs, damp, atol, btol, conlim, maxiter, show=False)[0]\n",
    "        dv.append(G_proj * x)\n",
    "    return (dv)\n",
    "\n",
    "\n",
    "def load_solver_from_disk(fname):\n",
    "    solver = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    with np.load(fname) as npz:\n",
    "        solver.vgrid.min_coords     = npz['min_coords']\n",
    "        solver.vgrid.node_intervals = npz['node_intervals']\n",
    "        solver.vgrid.npts           = npz['npts']\n",
    "        solver.uu[...]              = npz['uu']\n",
    "    return (solver)\n",
    "\n",
    "def load_solver_from_scratch(payload, station_id):\n",
    "    df_stations = payload['df_stations']\n",
    "    rho0, theta0, phi0 = geo2sph(\n",
    "        df_stations.loc[station_id, ['lat', 'lon', 'depth']].values\n",
    "    )\n",
    "    far_field  = init_farfield(payload['vmodel'])\n",
    "    near_field = init_nearfield(far_field, (rho0, theta0, phi0))\n",
    "    near_field.solve()\n",
    "    far_field.transfer_travel_times_from(near_field, (-rho0, theta0, phi0), set_alive=True)\n",
    "    far_field.solve()\n",
    "    np.savez_compressed(\n",
    "        os.path.join(payload['temp_dir'], f'{station_id}.npz'),\n",
    "        uu=far_field.uu,\n",
    "        min_coords=far_field.pgrid.min_coords,\n",
    "        node_intervals=far_field.pgrid.node_intervals,\n",
    "        npts=far_field.pgrid.npts\n",
    "    )\n",
    "    return (far_field)\n",
    "\n",
    "def process_station(args):\n",
    "        station_id, payload = args\n",
    "        df_obs      = payload['df_obs']\n",
    "        df_stations = payload['df_stations']\n",
    "        vmodel      = payload['vmodel']\n",
    "        events      = payload['events']\n",
    "        vcells      = payload['vcells']\n",
    "        colidp      = []\n",
    "        nsegs       = []\n",
    "        nonzerop    = []\n",
    "        dobs        = []\n",
    "        fname       = os.path.join(payload['temp_dir'], f'{station_id}.npz')\n",
    "        if os.path.isfile(fname):\n",
    "            solver = load_solver_from_disk(fname)\n",
    "        else:\n",
    "            solver = load_solver_from_scratch(payload, station_id)\n",
    "        tti = pykonal.LinearInterpolator3D(solver.pgrid, solver.uu)\n",
    "        for event_id in df_obs.loc[station_id].index.unique():\n",
    "            event = payload['events'].set_index('event_id').loc[event_id]\n",
    "            try:\n",
    "                rho_src, theta_src, phi_src = geo2sph(event[['lat', 'lon', 'depth']].values)\n",
    "                synthetic    = tti((rho_src, theta_src, phi_src))\n",
    "                residual     = df_obs.loc[(station_id, event_id), 'travel_time'] - synthetic\n",
    "                if abs(residual) > 3.0:\n",
    "                    continue\n",
    "                ray          = solver.trace_ray((rho_src, theta_src, phi_src))\n",
    "                idxs, counts = find_ray_idx(ray, vcells)\n",
    "                nseg = len(idxs)\n",
    "                nsegs.append(nseg)\n",
    "                dobs.append(residual)\n",
    "                for iseg in range(nseg):\n",
    "                    colidp.append(idxs[iseg])\n",
    "                    nonzerop.append(solver._get_step_size() * counts[iseg])\n",
    "            except pykonal.OutOfBoundsError as err:\n",
    "                continue\n",
    "        return (dobs, colidp, nsegs, nonzerop)\n",
    "        \n",
    "\n",
    "\n",
    "def load_argc():\n",
    "    '''\n",
    "    Return command line arguments.\n",
    "    '''\n",
    "    argc              = Arguments()\n",
    "    argc.event_file   = 'events.h5'\n",
    "    argc.network_file = 'network.h5'\n",
    "    return (argc)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    '''\n",
    "    Return parameter file parameters.\n",
    "    '''\n",
    "    params = dict(\n",
    "        latmin   = 32.4,\n",
    "        lonmin   = -120.1,\n",
    "        depmin   = -3,\n",
    "        nlat     = 105,\n",
    "        nlon     = 127,\n",
    "        nrad     = 34,\n",
    "        dlat     = 0.04,\n",
    "        dlon     = 0.04,\n",
    "        drad     = 1.0,\n",
    "        damp     = 0.0,\n",
    "        datafile = 'scecdc2018.nc',\n",
    "        phase    = 'P',\n",
    "        nsamp    = 10000, # Number of observations (arrivals) to sample.\n",
    "        ncell    = 600,  # Number of Voronoi cells per realization.\n",
    "        nreal    = 25,    # Number of realizations per iteration.\n",
    "        niter    = 1,    # Number of iterations.\n",
    "        nthreads = 8\n",
    "    )\n",
    "    return (params)\n",
    "\n",
    "\n",
    "def load_event_data(argc, params):\n",
    "    '''\n",
    "    Read and return *events* and *arrivals* tables from pandas.HDFStore.\n",
    "    '''\n",
    "    with pd.HDFStore(argc.event_file) as store:\n",
    "        df_events   = store['events']\n",
    "        df_arrivals = store['arrivals']\n",
    "    df_arrivals['station_id'] = df_arrivals['net'] + '.' + df_arrivals['sta']\n",
    "    df_arrivals = df_arrivals.drop(\n",
    "        columns=['net', 'sta']\n",
    "    ).set_index(\n",
    "        'phase'\n",
    "    ).loc[\n",
    "        params['phase']\n",
    "    ]\n",
    "    return (df_events, df_arrivals)\n",
    "\n",
    "\n",
    "def load_network_data(argc):\n",
    "    '''\n",
    "    Read and return *stations* table from pandas.HDFStore.\n",
    "    '''\n",
    "    with pd.HDFStore(argc.network_file) as store:\n",
    "        df_stations = store['stations']\n",
    "    df_stations['station_id'] = df_stations['net'] + '.' + df_stations['sta']\n",
    "    df_stations               = df_stations.set_index(\n",
    "        'station_id'\n",
    "    ).drop(\n",
    "        columns=['net', 'sta']\n",
    "    )\n",
    "    df_stations['depth']      = df_stations['elev'] * -1\n",
    "    return (df_stations)\n",
    "\n",
    "def load_initial_velocity_model(params):\n",
    "    grid = pykonal.Grid3D(coord_sys='spherical')\n",
    "    grid.min_coords     = geo2sph(\n",
    "        (\n",
    "            params['latmin'] + (params['nlat']-1)*params['dlat'], \n",
    "            params['lonmin'], \n",
    "            params['depmin'] + (params['nrad']-1)*params['drad']\n",
    "        )\n",
    "    )\n",
    "    grid.node_intervals = (\n",
    "        params['drad'], np.radians(params['dlat']), np.radians(params['dlon'])\n",
    "    )\n",
    "    grid.npts           = params['nrad'], params['nlat'], params['nlon']\n",
    "    velocity            = 6. * np.ones(grid.npts)\n",
    "    vmodel              = VelocityModel(grid, velocity)\n",
    "    return (vmodel)\n",
    "\n",
    "\n",
    "def sample_observed_data(params, payload):\n",
    "    df = payload['arrivals'].merge(\n",
    "        payload['events'][['time', 'event_id']],\n",
    "        on='event_id',\n",
    "        suffixes=('_arrival','_origin')\n",
    "    )\n",
    "    df['travel_time'] = (df['time_arrival'] - df['time_origin']).dt.total_seconds()\n",
    "    # Remove any arrivals at stations without metadata\n",
    "    df = df[df['station_id'].isin(payload['stations'].index.unique())]\n",
    "    return (\n",
    "        df.sort_values(\n",
    "            'station_id'\n",
    "        ).drop_duplicates( # There shouldn't be any duplicates in a clean data set.\n",
    "            subset=['station_id', 'event_id'], \n",
    "            keep=False\n",
    "        ).set_index(\n",
    "            ['station_id', 'event_id']\n",
    "        ).drop(\n",
    "            columns=['chan', 'time_arrival', 'time_origin']\n",
    "        ).sample(\n",
    "            n=params['nsamp']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time output = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel = output[0]\n",
    "for i in range(1, len(output)):\n",
    "    vel += output[i]\n",
    "vel /= len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel3d = vel.reshape((params['nrad'], params['nlat'], params['nlon']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seispy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sph2geo(arr):\n",
    "    '''\n",
    "    Map spherical coordinates to Cartesian coordinates.\n",
    "    '''\n",
    "    sph = np.array(arr, dtype=DTYPE_REAL)\n",
    "    geo = np.empty_like(sph)\n",
    "    geo[...,0] = np.degrees(np.pi/2 - sph[...,1])\n",
    "    geo[...,1] = np.degrees(sph[...,2])\n",
    "    geo[...,2] = EARTH_RADIUS - sph[...,0]\n",
    "    return (geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latmin              = params['latmin']\n",
    "lonmin              = params['lonmin']\n",
    "latmax              = params['latmin'] + (params['nlat']-1)*params['dlat']\n",
    "lonmax              = params['lonmin'] + (params['nlon']-1)*params['dlon']\n",
    "grid                = pykonal.Grid3D(coord_sys='spherical')\n",
    "grid.min_coords     = geo2sph((latmax, lonmin, params['depmin'] + (params['nrad']-1)*params['drad']))\n",
    "grid.node_intervals = params['drad'], np.radians(params['dlat']), np.radians(params['dlon'])\n",
    "grid.npts           = params['nrad'], params['nlat'], params['nlon']\n",
    "geo                 = sph2geo(grid.nodes)\n",
    "idx                 = -5\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "bm  = seispy.mapping.Basemap(\n",
    "    basekwargs=dict(\n",
    "        llcrnrlat=latmin,\n",
    "        llcrnrlon=lonmin,\n",
    "        urcrnrlat=latmax,\n",
    "        urcrnrlon=lonmax,\n",
    "        resolution='i'\n",
    "    ),\n",
    "    continent_color='1',\n",
    "    fill_color='1',\n",
    "    lake_color='1'\n",
    ")\n",
    "qmesh = bm.overlay_pcolormesh(\n",
    "    geo[idx,:,:,1].flatten(), \n",
    "    geo[idx,:,:,0].flatten(), \n",
    "    vel3d[idx,:,:].flatten(),\n",
    "    cmap=plt.get_cmap('jet')\n",
    ")\n",
    "bm.colorbar(qmesh)\n",
    "bm.drawcoastlines(zorder=2, linewidth=2)\n",
    "bm.add_faults(zorder=2, linewidth=0.5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
