{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pykonal\n",
    "import scipy.optimize\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import scipy.spatial\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "EARTH_RADIUS = 6371.\n",
    "DTYPE_REAL   = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class VelocityModel(object):\n",
    "    def __init__(self, grid, velocity):\n",
    "        self.grid     = grid\n",
    "        self.velocity = velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo2sph(arr):\n",
    "    '''\n",
    "    Map Geographical coordinates to spherical coordinates.\n",
    "    '''\n",
    "    geo = np.array(arr, dtype=DTYPE_REAL)\n",
    "    sph = np.empty_like(geo)\n",
    "    sph[...,0] = EARTH_RADIUS - geo[...,2]\n",
    "    sph[...,1] = np.pi/2 - np.radians(geo[...,0])\n",
    "    sph[...,2] = np.radians(geo[...,1])\n",
    "    return (sph)\n",
    "\n",
    "\n",
    "def sph2xyz(arr):\n",
    "    '''\n",
    "    Map spherical coordinates to Cartesian coordinates.\n",
    "    '''\n",
    "    sph = np.array(arr, dtype=DTYPE_REAL)\n",
    "    xyz = np.empty_like(sph)\n",
    "    xyz[...,0] = sph[...,0] * np.sin(sph[...,1]) * np.cos(sph[...,2])\n",
    "    xyz[...,1] = sph[...,0] * np.sin(sph[...,1]) * np.sin(sph[...,2])\n",
    "    xyz[...,2] = sph[...,0] * np.cos(sph[...,1])\n",
    "    return (xyz)\n",
    "\n",
    "def sph2geo(arr):\n",
    "    '''\n",
    "    Map spherical coordinates to geographic coordinates.\n",
    "    '''\n",
    "    sph = np.array(arr, dtype=DTYPE_REAL)\n",
    "    geo = np.empty_like(sph)\n",
    "    geo[...,0] = np.degrees(np.pi/2 - sph[...,1])\n",
    "    geo[...,1] = np.degrees(sph[...,2])\n",
    "    geo[...,2] = EARTH_RADIUS - sph[...,0]\n",
    "    return (geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    Main.\n",
    "    '''\n",
    "    argc                   = load_argc()\n",
    "    params                 = load_params()\n",
    "    df_events, df_arrivals = load_event_data(argc, params)\n",
    "    df_stations            = load_network_data(argc)\n",
    "    vmodel                 = load_initial_velocity_model(params)\n",
    "    df_arrivals            = sanitize_arrivals(df_arrivals, df_stations)\n",
    "    payload                = dict(\n",
    "        events   = df_events.sort_values('event_id').set_index('event_id'),\n",
    "        arrivals = df_arrivals.set_index('phase').loc[params['phase']],\n",
    "        stations = df_stations.set_index('station_id'),\n",
    "        vmodel   = vmodel\n",
    "    )\n",
    "    # Iteratively invert data\n",
    "    for i in range(params['niter']):\n",
    "        # Create a temporary directory to work in.\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            payload['temp_dir'] = temp_dir\n",
    "            # Update the velocity model.\n",
    "            vmodel = iterate_inversion(params, payload)\n",
    "        # Create the output directory if it doesn't exist.\n",
    "        if not os.path.isdir(argc.output_dir):\n",
    "            os.makedirs(argc.output_dir)\n",
    "        # Save the update velocity model to disk.\n",
    "        np.savez_compressed(\n",
    "            os.path.join(argc.output_dir, f'model_{params[\"phase\"]}.{i+1:03d}.npz'),\n",
    "            min_coords=vmodel.grid.min_coords,\n",
    "            node_intervals=vmodel.grid.node_intervals,\n",
    "            npts=vmodel.grid.npts,\n",
    "            vv=vmodel.velocity\n",
    "        )\n",
    "        # Update the payload with the new velocity model.\n",
    "        payload['vmodel'] = vmodel\n",
    "\n",
    "\n",
    "def generate_projection_matrix(grid, ncell=300):\n",
    "    '''\n",
    "    Generate the matrix to project each rectilinear grid node to its\n",
    "    host Voronoi cell.\n",
    "    '''\n",
    "    vcells = generate_voronoi_cells(grid, ncell)\n",
    "    dist   = scipy.spatial.distance.cdist(\n",
    "        sph2xyz(grid.nodes.reshape(-1, 3)), \n",
    "        sph2xyz(vcells)\n",
    "    )\n",
    "    colid = np.argmin(dist, axis=1)\n",
    "    rowid = np.arange(np.prod(grid.nodes.shape[:-1]))\n",
    "    \n",
    "    Gp = scipy.sparse.coo_matrix(\n",
    "        (np.ones(np.prod(grid.nodes.shape[:-1]),), (rowid, colid)),\n",
    "        shape=(np.prod(grid.nodes.shape[:-1]), ncell)\n",
    "    )\n",
    "    return (vcells, Gp)\n",
    "\n",
    "\n",
    "def generate_voronoi_cells(grid, ncell):\n",
    "    '''\n",
    "    Generate a random set of points representing the centers of Voronoi cells.\n",
    "    '''\n",
    "    delta = (grid.max_coords - grid.min_coords)\n",
    "    return (np.random.rand(ncell, 3) * delta + grid.min_coords)\n",
    "\n",
    "def find_ray_idx(ray, vcells):\n",
    "    '''\n",
    "    Determine the index of the Voronoi cell hosting each point on\n",
    "    the ray path.\n",
    "    '''\n",
    "    dist = scipy.spatial.distance.cdist(sph2xyz(ray), sph2xyz(vcells))\n",
    "    argmin = np.argmin(dist, axis=1)\n",
    "    idxs, counts = np.unique(argmin, return_counts=True)\n",
    "    return (idxs, counts)\n",
    "\n",
    "\n",
    "def init_farfield(vmodel):\n",
    "    '''\n",
    "    Initialize the far-field EikonalSolver with the given velocity model.\n",
    "    '''\n",
    "    far_field                      = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    far_field.vgrid.min_coords     = vmodel.grid.min_coords\n",
    "    far_field.vgrid.node_intervals = vmodel.grid.node_intervals\n",
    "    far_field.vgrid.npts           = vmodel.grid.npts\n",
    "    far_field.vv                   = vmodel.velocity\n",
    "    return (far_field)\n",
    "\n",
    "def init_nearfield(far_field, origin):\n",
    "    '''\n",
    "    Initialize the near-field EikonalSolver.\n",
    "    \n",
    "    :param origin: Station location in spherical coordinates.\n",
    "    :type origin: (float, float, float)\n",
    "    \n",
    "    :return: Near-field EikonalSolver\n",
    "    :rtype: pykonal.EikonalSolver\n",
    "    '''\n",
    "    drho                            = far_field.vgrid.node_intervals[0] / 5\n",
    "    near_field                      = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    near_field.vgrid.min_coords     = drho, 0, 0\n",
    "    near_field.vgrid.node_intervals = drho, np.pi/20, np.pi/20\n",
    "    near_field.vgrid.npts           = 100, 21, 40\n",
    "    near_field.transfer_velocity_from(far_field, origin)\n",
    "    vvi = pykonal.LinearInterpolator3D(near_field.vgrid, near_field.vv)\n",
    "\n",
    "    for it in range(near_field.pgrid.npts[1]):\n",
    "        for ip in range(near_field.pgrid.npts[2]):\n",
    "            idx = (0, it, ip)\n",
    "            near_field.uu[idx]     = near_field.pgrid[idx + (0,)] / vvi(near_field.pgrid[idx])\n",
    "            near_field.is_far[idx] = False\n",
    "            near_field.close.push(*idx)\n",
    "    return (near_field)\n",
    "\n",
    "\n",
    "def station_generator(payload):\n",
    "    for station_id in payload['df_obs'].index.unique(level='station_id'):\n",
    "        yield (station_id, payload)\n",
    "    \n",
    "    \n",
    "def iterate_inversion(params, payload):\n",
    "    '''\n",
    "    Invert data and update *vmodel*.\n",
    "    '''\n",
    "    ds = [] \n",
    "    # Iterate over number of realizations.\n",
    "    df_stations = payload['stations']\n",
    "    for i in range(params['nreal']):\n",
    "        print(f'Realization #{i+1}')\n",
    "        vcells, G_proj  = generate_projection_matrix(payload['vmodel'].grid, params['ncell'])\n",
    "        df_obs          = sample_observed_data(params, payload)\n",
    "        station_payload = dict(\n",
    "            temp_dir    = payload['temp_dir'],\n",
    "            df_obs      = df_obs,\n",
    "            df_stations = df_stations,\n",
    "            vmodel      = payload['vmodel'],\n",
    "            events      = payload['events'],\n",
    "            vcells      = vcells\n",
    "        )\n",
    "        with mp.Pool(processes=params['nthreads']) as pool:\n",
    "            pool_output = pool.map(process_station, station_generator(station_payload))\n",
    "\n",
    "        dobs         = np.array(sum([out[0] for out in pool_output], []))\n",
    "        col_idx_proj = np.array(sum([out[1] for out in pool_output], []))\n",
    "        nseg         = np.array(sum([out[2] for out in pool_output], []))\n",
    "        row_idx_proj = np.array([i for i in range(len(nseg)) for j in range(nseg[i])])\n",
    "        nonzero_proj = np.array(sum([out[3] for out in pool_output], []))\n",
    "\n",
    "        G = scipy.sparse.coo_matrix(\n",
    "            (nonzero_proj, (row_idx_proj, col_idx_proj)), \n",
    "            shape=(len(nseg), params['ncell'])\n",
    "        )\n",
    "        \n",
    "\n",
    "        atol    = 1e-3\n",
    "        btol    = 1e-4\n",
    "        maxiter = 100\n",
    "        conlim  = 50\n",
    "        damp    = 1.0\n",
    "\n",
    "        x       = scipy.sparse.linalg.lsmr(G, dobs, damp, atol, btol, conlim, maxiter, show=False)[0]\n",
    "        ds.append(G_proj * x)\n",
    "    vmodel = payload['vmodel']\n",
    "    ds = np.mean(ds, axis=0).reshape(vmodel.grid.npts)\n",
    "    vmodel.velocity = np.power((np.power(vmodel.velocity, -1) + ds), -1)\n",
    "    return (vmodel)\n",
    "\n",
    "\n",
    "def load_solver_from_disk(fname):\n",
    "    solver = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    with np.load(fname) as npz:\n",
    "        solver.vgrid.min_coords     = npz['min_coords']\n",
    "        solver.vgrid.node_intervals = npz['node_intervals']\n",
    "        solver.vgrid.npts           = npz['npts']\n",
    "        solver.uu[...]              = npz['uu']\n",
    "    return (solver)\n",
    "\n",
    "def load_solver_from_scratch(payload, station_id, tag=None):\n",
    "    df_stations = payload['df_stations']\n",
    "    rho0, theta0, phi0 = geo2sph(\n",
    "        df_stations.loc[station_id, ['lat', 'lon', 'depth']].values\n",
    "    )\n",
    "    far_field  = init_farfield(payload['vmodel'])\n",
    "    near_field = init_nearfield(far_field, (rho0, theta0, phi0))\n",
    "    near_field.solve()\n",
    "    far_field.transfer_travel_times_from(near_field, (-rho0, theta0, phi0), set_alive=True)\n",
    "    far_field.solve()\n",
    "    np.savez_compressed(\n",
    "        os.path.join(\n",
    "            payload['temp_dir'],\n",
    "            f'{station_id}.npz' if tag is None else f'{station_id}.{tag}.npz'\n",
    "        ),\n",
    "        uu=far_field.uu,\n",
    "        min_coords=far_field.pgrid.min_coords,\n",
    "        node_intervals=far_field.pgrid.node_intervals,\n",
    "        npts=far_field.pgrid.npts\n",
    "    )\n",
    "    return (far_field)\n",
    "\n",
    "def process_station(args):\n",
    "        station_id, payload = args\n",
    "        df_obs      = payload['df_obs']\n",
    "        df_stations = payload['df_stations']\n",
    "        df_events   = payload['events']\n",
    "        vmodel      = payload['vmodel']\n",
    "        events      = payload['events']\n",
    "        vcells      = payload['vcells']\n",
    "        colidp      = []\n",
    "        nsegs       = []\n",
    "        nonzerop    = []\n",
    "        dobs        = []\n",
    "        fname       = os.path.join(payload['temp_dir'], f'{station_id}.npz')\n",
    "        if os.path.isfile(fname):\n",
    "            solver = load_solver_from_disk(fname)\n",
    "        else:\n",
    "            solver = load_solver_from_scratch(payload, station_id)\n",
    "        tti = pykonal.LinearInterpolator3D(solver.pgrid, solver.uu)\n",
    "        for event_id in df_obs.loc[station_id].index.unique():\n",
    "            event = df_events.loc[event_id]\n",
    "            try:\n",
    "                rho_src, theta_src, phi_src = geo2sph(event[['lat', 'lon', 'depth']].values)\n",
    "                synthetic    = tti((rho_src, theta_src, phi_src))\n",
    "                residual     = df_obs.loc[(station_id, event_id), 'travel_time'] - synthetic\n",
    "                if abs(residual) > 3.0:\n",
    "                    continue\n",
    "                ray          = solver.trace_ray((rho_src, theta_src, phi_src))\n",
    "                idxs, counts = find_ray_idx(ray, vcells)\n",
    "                nseg = len(idxs)\n",
    "                nsegs.append(nseg)\n",
    "                dobs.append(residual)\n",
    "                for iseg in range(nseg):\n",
    "                    colidp.append(idxs[iseg])\n",
    "                    nonzerop.append(solver._get_step_size() * counts[iseg])\n",
    "            except pykonal.OutOfBoundsError as err:\n",
    "                continue\n",
    "        return (dobs, colidp, nsegs, nonzerop)\n",
    "        \n",
    "\n",
    "\n",
    "def load_argc():\n",
    "    '''\n",
    "    Return command line arguments.\n",
    "    '''\n",
    "    argc              = Arguments()\n",
    "    argc.event_file   = 'events.h5'\n",
    "    argc.network_file = 'network.h5'\n",
    "    argc.output_dir   = os.path.join(os.path.abspath('.'), 'output')\n",
    "    return (argc)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    '''\n",
    "    Return parameter file parameters.\n",
    "    '''\n",
    "    params = dict(\n",
    "        latmin   = 32.4,\n",
    "        lonmin   = -120.1,\n",
    "        depmin   = -3,\n",
    "        nlat     = 105,\n",
    "        nlon     = 127,\n",
    "        nrad     = 34,\n",
    "        dlat     = 0.04,\n",
    "        dlon     = 0.04,\n",
    "        drad     = 1.0,\n",
    "        damp     = 0.0,\n",
    "        datafile = 'scecdc2018.nc',\n",
    "        phase    = 'P',\n",
    "        nsamp    = 5000, # Number of observations (arrivals) to sample.\n",
    "        ncell    = 600,  # Number of Voronoi cells per realization.\n",
    "        nreal    = 100,    # Number of realizations per iteration.\n",
    "        niter    = 1,    # Number of iterations.\n",
    "        nthreads = 24\n",
    "    )\n",
    "    return (params)\n",
    "\n",
    "\n",
    "def load_event_data(argc, params):\n",
    "    '''\n",
    "    Read and return *events* and *arrivals* tables from pandas.HDFStore.\n",
    "    '''\n",
    "    with pd.HDFStore(argc.event_file) as store:\n",
    "        df_events   = store['events']\n",
    "        df_arrivals = store['arrivals']\n",
    "    df_arrivals['station_id'] = df_arrivals['net'] + '.' + df_arrivals['sta']\n",
    "    df_arrivals               = df_arrivals = df_arrivals.drop(\n",
    "        columns=['net', 'sta']\n",
    "    )\n",
    "    return (df_events, df_arrivals)\n",
    "\n",
    "\n",
    "def sanitize_arrivals(df_arrivals, df_stations):\n",
    "    return (\n",
    "        df_arrivals[\n",
    "            df_arrivals['station_id'].isin(df_stations['station_id'].unique())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def load_network_data(argc):\n",
    "    '''\n",
    "    Read and return *stations* table from pandas.HDFStore.\n",
    "    '''\n",
    "    with pd.HDFStore(argc.network_file) as store:\n",
    "        df_stations = store['stations']\n",
    "    df_stations['station_id'] = df_stations['net'] + '.' + df_stations['sta']\n",
    "    df_stations               = df_stations.drop(columns=['net', 'sta'])\n",
    "    df_stations['depth']      = df_stations['elev'] * -1\n",
    "    return (df_stations)\n",
    "    \n",
    "\n",
    "def load_initial_velocity_model(params):\n",
    "    grid = pykonal.Grid3D(coord_sys='spherical')\n",
    "    grid.min_coords     = geo2sph(\n",
    "        (\n",
    "            params['latmin'] + (params['nlat']-1)*params['dlat'], \n",
    "            params['lonmin'], \n",
    "            params['depmin'] + (params['nrad']-1)*params['drad']\n",
    "        )\n",
    "    )\n",
    "    grid.node_intervals = (\n",
    "        params['drad'], np.radians(params['dlat']), np.radians(params['dlon'])\n",
    "    )\n",
    "    grid.npts           = params['nrad'], params['nlat'], params['nlon']\n",
    "    velocity            = 6. * np.ones(grid.npts)\n",
    "    vmodel              = VelocityModel(grid, velocity)\n",
    "    return (vmodel)\n",
    "\n",
    "\n",
    "def sample_observed_data(params, payload):\n",
    "    df = payload['arrivals'].merge(\n",
    "        payload['events']['time'],\n",
    "        left_on='event_id',\n",
    "        right_index=True,\n",
    "        suffixes=('_arrival','_origin')\n",
    "    )\n",
    "    df['travel_time'] = (df['time_arrival'] - df['time_origin']).dt.total_seconds()\n",
    "    # Remove any arrivals at stations without metadata\n",
    "    df = df[df['station_id'].isin(payload['stations'].index.unique())]\n",
    "    return (\n",
    "        df.sort_values(\n",
    "            'station_id'\n",
    "        ).drop_duplicates( # There shouldn't be any duplicates in a clean data set.\n",
    "            subset=['station_id', 'event_id'], \n",
    "            keep=False\n",
    "        ).set_index(\n",
    "            ['station_id', 'event_id']\n",
    "        ).drop(\n",
    "            columns=['chan', 'time_arrival', 'time_origin']\n",
    "        ).sample(\n",
    "            n=params['nsamp']\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def load_velocity_from_file(fname):\n",
    "    grid = pykonal.Grid3D(coord_sys='spherical')\n",
    "    with np.load(fname) as infile:\n",
    "        grid.min_coords     = infile['min_coords']\n",
    "        grid.node_intervals = infile['node_intervals']\n",
    "        grid.npts           = infile['npts']\n",
    "        vmodel              = VelocityModel(grid=grid, velocity=infile['vv'])\n",
    "    return (vmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time output = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "import seispy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmodel = load_velocity_from_file('output/model_P.001.npz')\n",
    "grid                 = vmodel.grid\n",
    "latmax, lonmin, dmax = seispy.coords.as_spherical(grid.min_coords).to_geographic()\n",
    "latmin, lonmax, dmin = seispy.coords.as_spherical(grid.max_coords).to_geographic()\n",
    "geo                  = seispy.coords.as_spherical(grid.nodes).to_geographic()\n",
    "idx                  = -5\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "bm  = seispy.mapping.Basemap(\n",
    "    basekwargs=dict(\n",
    "        llcrnrlat=latmin,\n",
    "        llcrnrlon=lonmin,\n",
    "        urcrnrlat=latmax,\n",
    "        urcrnrlon=lonmax,\n",
    "        resolution='c'\n",
    "    ),\n",
    "    continent_color='1',\n",
    "    fill_color='1',\n",
    "    lake_color='1'\n",
    ")\n",
    "qmesh = bm.overlay_pcolormesh(\n",
    "    geo[idx,:,:,1].flatten(), \n",
    "    geo[idx,:,:,0].flatten(), \n",
    "    vmodel.velocity[idx,:,:].flatten(),\n",
    "    cmap=plt.get_cmap('jet_r')\n",
    ")\n",
    "bm.colorbar(qmesh)\n",
    "bm.drawcoastlines(zorder=2, linewidth=2)\n",
    "# bm.add_faults(zorder=2, linewidth=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "latmin, latmax = 32, 34\n",
    "lonmin, lonmax = -118, -116\n",
    "dmin, dmax     = -1, 20\n",
    "nevents        = 10\n",
    "    \n",
    "def create_stations(latmin, latmax, lonmin, lonmax):\n",
    "    coords = np.meshgrid(\n",
    "        np.linspace(latmin, latmax, 6),\n",
    "        np.linspace(lonmin, lonmax, 6)\n",
    "    )\n",
    "    df = pd.DataFrame()\n",
    "    df['lat']  = coords[0].flatten()\n",
    "    df['lon']  = coords[1].flatten()\n",
    "    df['elev'] = 0\n",
    "    df['depth'] = -df['elev']\n",
    "    df['station_id'] = '__'\n",
    "    for inet in range(6):\n",
    "        for ista in range(6):\n",
    "            idx = inet*6 + ista\n",
    "            df.loc[idx, 'station_id'] = chr(65+inet) + '.' + chr(65+ista)\n",
    "    return (df)\n",
    "\n",
    "def create_events(nevents, latmin, latmax, lonmin, lonmax, dmin, dmax):\n",
    "    events = np.random.rand(nevents, 3) * [latmax-latmin, lonmax-lonmin, dmax-dmin] + [latmin, lonmin, dmin]\n",
    "    df = pd.DataFrame(columns=['event_id', 'lat', 'lon', 'depth', 'time', 'rms'])\n",
    "    df['lat']   = np.random.rand(nevents) * (latmax-latmin) + latmin\n",
    "    df['lon']   = np.random.rand(nevents) * (lonmax-lonmin) + lonmin\n",
    "    df['depth'] = np.random.rand(nevents) * (dmax-dmin) + dmin\n",
    "    df['time']  = np.random.rand(nevents) * (\n",
    "        pd.to_datetime('now') - pd.to_datetime(0)\n",
    "    ).total_seconds()\n",
    "    df['event_id'] = df.index + 1\n",
    "    return (df)\n",
    "    \n",
    "\n",
    "def create_arrivals(df_events, df_stations, vp=6, vs=3.47):\n",
    "    df = pd.DataFrame(columns=['event_id', 'station_id', 'phase', 'time'])\n",
    "    for event_idx, event in df_events.iterrows():\n",
    "        df_stations['dist'] = scipy.spatial.distance.cdist(\n",
    "            sph2xyz(geo2sph(df_stations[['lat', 'lon', 'depth']])),\n",
    "            sph2xyz(geo2sph([event[['lat', 'lon', 'depth']]]))\n",
    "        )\n",
    "        df_append = df_stations[['station_id']].copy()\n",
    "        df_append['time'] = event['time'] + df_stations['dist'] / vp\n",
    "        df_append['phase'] = 'P'\n",
    "        df_append['event_id'] = event['event_id']\n",
    "        df = df.append(df_append, ignore_index=True, sort=True)\n",
    "        df_append = df_stations[['station_id']].copy()\n",
    "        df_append['time'] = event['time'] + df_stations['dist'] / vs\n",
    "        df_append['phase'] = 'S'\n",
    "        df_append['event_id'] = event['event_id']\n",
    "        df = df.append(df_append, ignore_index=True, sort=True)\n",
    "    return (df)\n",
    "\n",
    "def create_velocity_models(latmin, latmax, lonmin, lonmax, dmin, dmax, vp=6, vs=3.47):\n",
    "    grid = pykonal.Grid3D(coord_sys='spherical')\n",
    "    grid.min_coords = geo2sph((latmax, lonmin, dmax))\n",
    "    grid.npts       = 41, 81, 81\n",
    "    grid.node_intervals = (geo2sph((latmin, lonmax, dmin)) - grid.min_coords) / (grid.npts - 1)\n",
    "    vmodel_p        = VelocityModel(grid=grid, velocity=vp*np.ones(grid.npts))\n",
    "    vmodel_s        = VelocityModel(grid=grid, velocity=vs*np.ones(grid.npts))\n",
    "    return (vmodel_p, vmodel_s)\n",
    "\n",
    "df_stations = create_stations(latmin, latmax, lonmin, lonmax)\n",
    "df_events   = create_events(nevents, latmin, latmax, lonmin, lonmax, dmin, dmax)\n",
    "df_arrivals = create_arrivals(df_events, df_stations)\n",
    "vmodel_p, vmodel_s = create_velocity_models(latmin, latmax, lonmin, lonmax, dmin, dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_events(\n",
    "    df_arrivals, \n",
    "    df_stations, \n",
    "    vmodel_p, \n",
    "    vmodel_s, \n",
    "#     bounds=((latmin, latmax), (lonmin, lonmax), (dmin, dmax), (0, (pd.to_datetime('now')-pd.to_datetime(0)).total_seconds()))\n",
    "):\n",
    "    '''\n",
    "    df_arrivals :: pandas.DataFrame :: Arrival data. Must include \n",
    "        (event_id, station_id, phase, time) fields with (int, str, str, \n",
    "        float) dtypes, respectively.\n",
    "    df_stations :: pandas.DataFrame :: Network geometry data. Must\n",
    "        include (station_id, lat, lon, depth) fields with (str, float, \n",
    "        float, float) dtypes, respectively.\n",
    "    vmodel_p :: VelocityModel :: P-wave velocity model.\n",
    "    vmodel_s :: VelocityModel :: S-wave velocity model.\n",
    "    \n",
    "    return :: pandas.DataFrame :: Event locations. Includes (event_id, \n",
    "        lat, lon, depth, res) fields with (int, float, float, float, \n",
    "        float) dtypes, respectively.\n",
    "    '''\n",
    "    latmax, lonmin, dmax = sph2geo(vmodel_p.grid.min_coords)\n",
    "    latmin, lonmax, dmin = sph2geo(vmodel_p.grid.max_coords)\n",
    "    bounds = (\n",
    "        (latmin, latmax),\n",
    "        (lonmin, lonmax),\n",
    "        (dmin, dmax),\n",
    "        (0, (pd.to_datetime('now')-pd.to_datetime(0)).total_seconds())\n",
    "    )\n",
    "    df_events = pd.DataFrame(columns=['event_id', 'lat', 'lon', 'depth', 'time', 'res'])\n",
    "#     with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    temp_dir = '/export/shake/malcolcw/scratch/traveltimes'\n",
    "    for event_id in df_arrivals['event_id'].unique():\n",
    "        print(f'Locating event #{event_id}')\n",
    "        location = locate_event(\n",
    "            df_arrivals.set_index('event_id').loc[event_id],\n",
    "            df_stations,\n",
    "            vmodel_p,\n",
    "            vmodel_s,\n",
    "            temp_dir,\n",
    "            bounds\n",
    "        )\n",
    "        df_append             = pd.DataFrame(\n",
    "            [location.x], \n",
    "            columns=['lat', 'lon', 'depth', 'time']\n",
    "        )\n",
    "        df_append['res']      = location.fun\n",
    "        df_append['event_id'] = event_id\n",
    "        df_events = df_events.append(\n",
    "            df_append, ignore_index=True, sort=True\n",
    "        )\n",
    "    return (df_events)\n",
    "\n",
    "def locate_event(df_arrivals, df_stations, vmodel_p, vmodel_s, temp_dir, bounds):\n",
    "        tti = dict()\n",
    "        for arrival_idx, arrival in df_arrivals.iterrows():\n",
    "            station_id, phase = arrival[['station_id', 'phase']]\n",
    "            fname = os.path.join(temp_dir, f'{station_id}.{phase}.npz')\n",
    "            if not os.path.isfile(fname):\n",
    "                payload = dict(\n",
    "                    temp_dir=temp_dir,\n",
    "                    df_stations=df_stations.set_index('station_id'),\n",
    "                    vmodel=vmodel_p if phase == 'P' else vmodel_s\n",
    "                )\n",
    "                solver = load_solver_from_scratch(payload, station_id, tag=phase)\n",
    "            else:\n",
    "                solver = load_solver_from_disk(fname)\n",
    "            if station_id not in tti:\n",
    "                tti[station_id] = dict()\n",
    "            tti[station_id][phase] = pykonal.LinearInterpolator3D(solver.pgrid, solver.uu)\n",
    "        return (\n",
    "            scipy.optimize.differential_evolution(\n",
    "                cost_function, \n",
    "                bounds, \n",
    "                args=(df_arrivals, tti), polish=True)\n",
    "        )\n",
    "\n",
    "def cost_function(loc, *args):\n",
    "    lat, lon, depth, time = loc\n",
    "    df_arrivals, tti = args\n",
    "    try:\n",
    "        residuals = np.array([\n",
    "            tti[arrival['station_id']][arrival['phase']](geo2sph((lat, lon, depth))) \n",
    "            + time \n",
    "            - arrival['time'] \n",
    "            for idx, arrival in df_arrivals.iterrows()\n",
    "        ])\n",
    "    except pykonal.OutOfBoundsError:\n",
    "        return (np.inf)\n",
    "    return (np.median(np.abs(residuals)))\n",
    "        \n",
    "\n",
    "# loc = locate_events(df_arrivals, df_stations, vmodel_p, vmodel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argc                   = load_argc()\n",
    "params                 = load_params()\n",
    "df_events, df_arrivals = load_event_data(argc, params)\n",
    "df_stations            = load_network_data(argc)\n",
    "df_arrivals            = sanitize_arrivals(df_arrivals, df_stations)\n",
    "\n",
    "df_arrivals['time']       = seispy.pandas.time.to_epoch(df_arrivals['time']) * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmodel_p = load_velocity_from_file('output/model_P.001.npz')\n",
    "vmodel_s = load_velocity_from_file('output/model_S.001.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loc = locate_events(\n",
    "    df_arrivals.set_index('event_id').loc[df_arrivals['event_id'].unique()[-2:]].reset_index(),\n",
    "    df_stations,\n",
    "    vmodel_p,\n",
    "    vmodel_s\n",
    ")\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.set_index('event_id').loc[df_arrivals['event_id'].unique()[-2:]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arrivals.set_index('phase').loc['P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
